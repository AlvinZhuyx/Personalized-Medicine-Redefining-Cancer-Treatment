{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from data_preprocessing import *\n",
    "from word_embedding_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID    Gene             Variation  \\\n",
      "0  0  FAM58A  Truncating Mutations   \n",
      "1  1     CBL                 W802*   \n",
      "2  2     CBL                 Q249E   \n",
      "3  3     CBL                 N454D   \n",
      "4  4     CBL                 L399V   \n",
      "\n",
      "                                                Text  \n",
      "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
      "1   Abstract Background  Non-small cell lung canc...  \n",
      "2   Abstract Background  Non-small cell lung canc...  \n",
      "3  Recent evidence has demonstrated that acquired...  \n",
      "4  Oncogenic mutations in the monomeric Casitas B...  \n"
     ]
    }
   ],
   "source": [
    "[all_data, train_size, test_size, train_x, train_y, test_x] = util.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[allText, sentences] = data_preprocess(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    cyclindependent kinases cdks regulate variety ...\n",
      "1    abstract background nonsmall cell lung cancer ...\n",
      "2    abstract background nonsmall cell lung cancer ...\n",
      "3    recent evidence demonstrated acquired uniparen...\n",
      "4    oncogenic mutations monomeric casitas blineage...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(allText.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = Doc2VecParam(3, 6, 201,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_INPUT_DIM=200\n",
    "param = Doc2VecParam(1, 5, 600, 1e-4, 5, 4, 30, 1)\n",
    "filename='../model/doc2vec/docEmbeddings_30_load_all.d2v'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d8185a4cec46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTextModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/CS249/UCLA-CS249-project/src/word_embedding_load.py\u001b[0m in \u001b[0;36mgetTextModel\u001b[0;34m(param, filename)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetTextModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2VecParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../model/doc2vec/docEmbeddings_30_load_all.d2v'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "temp = getTextModel(param, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextVec(text_model, train_size, test_size, TEXT_INPUT_DIM = 200):\n",
    "    text_train_arrays = np.zeros((train_size, TEXT_INPUT_DIM))\n",
    "    text_test_arrays = np.zeros((test_size, TEXT_INPUT_DIM))\n",
    "    for i in range(train_size):\n",
    "        text_train_arrays[i] = text_model.docvecs['Text_'+str(i)]\n",
    "    j = 0\n",
    "    for i in range(train_size, test_size + train_size):\n",
    "        text_test_arrays[j] = text_model.docvecs['Text_'+str(i)]\n",
    "        j += 1\n",
    "    return text_train_arrays, text_test_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test_arrays, text_test_arrays = getTextVec(temp, train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_test_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the vector representation for the Gene, the length of the vector is compressed by SVD with default input dimension 25\n",
    "@param: \n",
    "    all_data,\n",
    "    svd, TruncatedSVD model from sklearn\n",
    "@return: truncated_one_hot_gene, gene vector representation\n",
    "\n",
    "'''\n",
    "def getGeneVec(all_data, svd):\n",
    "    one_hot_gene = pd.get_dummies(all_data['Gene'])\n",
    "    truncated_one_hot_gene = svd.fit_transform(one_hot_gene.values)\n",
    "    return truncated_one_hot_gene\n",
    "\n",
    "'''\n",
    "Get the vector representation for the variation type, the length of the vector is compressed by SVD with default input dimension 25\n",
    "@param: \n",
    "    all_data,\n",
    "    svd, TruncatedSVD model from sklearn\n",
    "@return: truncated_one_hot_variation, variation vector representation\n",
    "\n",
    "'''\n",
    "def getVariationVec(all_data, svd):\n",
    "    one_hot_variation = pd.get_dummies(all_data['Variation'])\n",
    "    truncated_one_hot_variation = svd.fit_transform(one_hot_variation.values)\n",
    "    return truncated_one_hot_variation\n",
    "\n",
    "GENE_INPUT_DIM=25\n",
    "TEXT_INPUT_DIM=200\n",
    "svd = TruncatedSVD(n_components=25, n_iter=GENE_INPUT_DIM, random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = getTextModel(param, filename)\n",
    "truncated_one_hot_gene = getGeneVec(all_data, svd)\n",
    "truncated_one_hot_variation = getVariationVec(all_data, svd)\n",
    "text_train_arrays, text_test_arrays = getTextVec(text_model, train_size, test_size, TEXT_INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.hstack((truncated_one_hot_gene[:train_size], truncated_one_hot_variation[:train_size], text_train_arrays))\n",
    "test_set = np.hstack((truncated_one_hot_gene[train_size:], truncated_one_hot_variation[train_size:], text_test_arrays))\n",
    "encoded_y = pd.get_dummies(train_y)\n",
    "encoded_y = np.array(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truncated_one_hot_gene[:train_size].shape)\n",
    "print(truncated_one_hot_variation[:train_size].shape)\n",
    "print(text_train_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
