agenda: 
1, environment setting
2, 分工
3, presentation






summary:

1, introduction
	1.1, problem statement
	1.2, methods
	
	why xg-boost?
		//https://www.zhihu.com/question/41354392
		//http://blog.csdn.net/shenxiaoming77/article/details/51542982

	other algorithms?

	1.3 contribution
		what we do



2, DATA OVERVIEW
TODO:
***DATA STATS***
***VISUALIZATION***

3, EVALUATION

3.1 Analysis of the Kaggle scoring issue
	--different sets of data,
	--different distribution, uneven distribution
	--stage 1 and stage 2 not consistent
	--late submission have different results than on-going results
	
	3.*, DATA STATS, VISUALIZATION

3.2 public score vs private score
	--public score have most data, reliable
	--others either without label, or lack of data
	--different distribution

4, FEATURE SELECTION
TODO:
************EXPERIMENT 1************
the effect of introducing external data -- naive classfication to support the performance gain.
(feature with external data features should be better than non-external-data features!!!)
(length of features// 25 + 25 + 200?)


metrics: accuracy on testset, confusion matrix, 1 vs the-other

	2.1 introduction of outside data
	2.2 parameters tuning, length of features
	optional: other models, (TF-IDF, word bag, BM25...)



5, CLASSIFICATION MODELS

why we choose the model?
 => NN overfitting with limited data
 => we turn to XG-BOOST

setup protocol!!!

************EXPERIMENT 2************
***call APIs to compare the results***
SVM, Naive Bayes, random forest...

METRICS:
	log score,
	accuracy,
	confusion matrix,
	multi-class ROC,
	etc...


why we give up NN, with training curve.

6, future work
why? practical, significance to locate the literature for professional people, 1+2 -> 3







