{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zhuya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from data_preprocessing import *\n",
    "from word_embedding_load import *\n",
    "from classification import *\n",
    "from xgboost_classifier import *\n",
    "from testaccuracy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_data, train_size, test_size, train_x, train_y, test_x] = util.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data_preprocess(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Text_INPUT_DIM=200\n",
    "param = util.Doc2VecParam(1, 30, 200, 1e-4, 5, 4, 30, 1)\n",
    "filename='../model/doc2vec/docEmbeddings_win30_load_all.d2v'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENE_INPUT_DIM=25\n",
    "TEXT_INPUT_DIM=200\n",
    "svd = TruncatedSVD(n_components=25, n_iter=GENE_INPUT_DIM, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Unable to find file: ../data/bio_nlp_vec/PubMed-shuffle-win-30.bin\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a4423dd70d4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTextModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../data/bio_nlp_vec/PubMed-shuffle-win-30.bin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtruncated_one_hot_gene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetGeneVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtruncated_one_hot_variation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetVariationVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext_train_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_test_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTextVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT_INPUT_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wel' is not defined"
     ]
    }
   ],
   "source": [
    "text_model = getTextModel(sentences, param, filename, source_file = \"../data/bio_nlp_vec/PubMed-shuffle-win-30.bin\")\n",
    "truncated_one_hot_gene = getGeneVec(all_data, svd)\n",
    "truncated_one_hot_variation = getVariationVec(all_data, svd)\n",
    "text_train_arrays, text_test_arrays = getTextVec(text_model, train_size, test_size, TEXT_INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3689, 200)\n",
      "(986, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.24369812, -1.04835904, -0.16700989, -1.30228102, -2.53944564,\n",
       "        3.06678963,  1.13737857, -0.94596148,  3.64967752,  0.76880342,\n",
       "       -4.1155076 , -0.58414513,  1.25717568,  0.18603103, -1.76679933,\n",
       "       -0.89988571, -0.53223836, -2.67734075,  1.5813092 ,  1.98253083,\n",
       "        2.28471136, -2.50079465,  1.94719625,  0.97214204, -1.24454093,\n",
       "       -0.41878808,  0.77878654, -0.91600305, -0.04947303,  0.62109476,\n",
       "       -0.22061618, -1.7253691 , -0.61084867,  1.74578667, -1.657812  ,\n",
       "       -1.20975828,  2.88858962,  1.70916057,  0.43557191,  1.61785996,\n",
       "        1.35576653,  2.79551506,  4.17269993, -1.20390821,  0.42969212,\n",
       "       -1.02026963,  0.24319248, -1.1995635 ,  0.97002679,  0.65847927,\n",
       "        1.86286092,  0.86462218, -2.63885283, -1.0137831 , -0.55161458,\n",
       "       -3.31917238, -0.75057697, -3.15323162,  0.95074302,  1.94172704,\n",
       "       -0.75874567,  1.87889767, -2.58744144,  2.02376413, -1.89029646,\n",
       "        4.7937336 ,  2.41782141,  3.03882504,  0.31665963, -2.47676969,\n",
       "        3.03614998, -0.06956459, -0.00620902, -2.70317936, -1.29895926,\n",
       "        2.87593913, -0.84940374, -2.6172545 , -1.42618811, -1.67377865,\n",
       "       -1.27473986, -0.6296047 , -0.85856754, -0.53802103,  0.68271065,\n",
       "       -0.48186815, -2.33849335,  2.0226078 ,  1.42586803,  1.93348336,\n",
       "        0.14262024,  2.4763639 , -4.6013217 , -3.38038683,  1.3547821 ,\n",
       "       -0.9163723 ,  2.12822223, -1.46824515, -1.34849906,  0.20019743,\n",
       "        0.26928908,  0.73610741, -0.82379162,  2.76396036,  4.66620398,\n",
       "        2.57717371, -2.95062327,  3.92748141, -1.74903321, -1.51893616,\n",
       "        2.82710481, -4.07605743, -3.34564304, -4.34362459, -1.31907213,\n",
       "        1.46425772,  0.89163625, -2.10327697, -0.08287898, -2.22111678,\n",
       "        0.42150626, -0.99330908, -1.38268566,  1.10964072, -4.03643465,\n",
       "       -1.31352353,  1.1201272 ,  2.73598981, -2.26505494,  2.21162534,\n",
       "        1.8607918 , -1.66040576,  0.86926597, -1.90855122, -0.84748864,\n",
       "        2.39681792,  2.93476772,  1.95948577,  2.84322333,  1.57476759,\n",
       "        1.49825871, -1.10029519, -2.21789551,  0.68117553,  0.0368939 ,\n",
       "        1.62731814, -1.48541641,  6.0165906 , -2.75908089, -1.43598938,\n",
       "       -5.20301533,  0.99528199, -3.51092601,  4.80351257, -1.13365185,\n",
       "        6.08225489, -2.30606818, -1.34818649, -0.28194696,  0.90648103,\n",
       "        0.72212261,  3.03351712, -0.93380046,  4.74595261, -3.2459712 ,\n",
       "       -0.45398557,  0.50367403, -1.30654085,  1.96534252, -2.11831117,\n",
       "        2.83551598,  2.48494768,  2.22846603, -0.40946385, -3.23300338,\n",
       "        1.43496764,  1.16832435, -2.29983377, -2.01355815, -1.42718017,\n",
       "        0.88171905,  1.9725498 , -0.25099111,  3.80346155, -2.38222504,\n",
       "        2.35856199,  3.69339275, -4.84366131, -0.87906265,  3.12255454,\n",
       "        0.99172795,  0.2520898 ,  0.75449103, -1.30847991,  1.27679241,\n",
       "        0.52493298, -0.53591967,  1.25490487, -1.7214576 , -0.14294872])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_train_arrays.shape)\n",
    "print(text_test_arrays.shape)\n",
    "text_train_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = np.hstack((truncated_one_hot_gene[:train_size], truncated_one_hot_variation[:train_size], text_train_arrays))\n",
    "test_set = np.hstack((truncated_one_hot_gene[train_size:], truncated_one_hot_variation[train_size:], text_test_arrays))\n",
    "encoded_y = pd.get_dummies(train_y)\n",
    "encoded_y = np.array(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3689, 250)\n",
      "(986, 250)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   4.18523246e-19,   1.82140582e-19,\n",
       "         5.52932734e-29,   9.01317672e-25,   1.47967745e-22,\n",
       "        -8.38240178e-21,   2.00300590e-21,   9.74158370e-21,\n",
       "        -9.34683441e-21,   1.91083889e-20,   6.55003880e-19,\n",
       "        -1.09276438e-17,  -1.56730196e-18,  -2.12913704e-18,\n",
       "        -4.51096312e-18,  -3.82900024e-19,   1.15894157e-17,\n",
       "         1.59938703e-17,   3.58735292e-17,  -3.35304994e-18,\n",
       "         1.68462844e-17,   6.76851697e-18,   5.86047343e-17,\n",
       "         7.80129580e-21])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0, 25:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3689, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuya\\Desktop\\semester 1\\249 data structure\\project\\src\\classification.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_initializer=\"normal\", input_dim=250)`\n",
      "  model.add(Dense(256, input_dim=Text_INPUT_DIM+ Gene_INPUT_DIM + Variation_INPUT_DIM, init='normal', activation='relu'))\n",
      "C:\\Users\\zhuya\\Desktop\\semester 1\\249 data structure\\project\\src\\classification.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  model.add(Dense(256, init='normal', activation='relu'))\n",
      "C:\\Users\\zhuya\\Desktop\\semester 1\\249 data structure\\project\\src\\classification.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(80, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  model.add(Dense(80, init='normal', activation='relu'))\n",
      "C:\\Users\\zhuya\\Desktop\\semester 1\\249 data structure\\project\\src\\classification.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(9, activation=\"softmax\", kernel_initializer=\"normal\")`\n",
      "  model.add(Dense(9, init='normal', activation=\"softmax\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               64256     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                20560     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 729       \n",
      "=================================================================\n",
      "Total params: 151,337\n",
      "Trainable params: 151,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this is the 4 layer full-connected nerual network model\n",
    "model = nn_baseline_model(TEXT_INPUT_DIM, GENE_INPUT_DIM, GENE_INPUT_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try.h5\n",
      "begin training\n",
      "\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 13s - loss: 2.2319 - acc: 0.06 - ETA: 1s - loss: 2.1457 - acc: 0.1597 - ETA: 0s - loss: 2.0552 - acc: 0.201 - ETA: 0s - loss: 2.0015 - acc: 0.228 - ETA: 0s - loss: 1.9773 - acc: 0.244 - 0s - loss: 1.9618 - acc: 0.2538 - val_loss: 1.6690 - val_acc: 0.4201\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.8058 - acc: 0.390 - ETA: 0s - loss: 1.7544 - acc: 0.355 - ETA: 0s - loss: 1.7628 - acc: 0.349 - ETA: 0s - loss: 1.7414 - acc: 0.364 - ETA: 0s - loss: 1.7340 - acc: 0.366 - ETA: 0s - loss: 1.7162 - acc: 0.370 - 0s - loss: 1.7145 - acc: 0.3697 - val_loss: 1.4633 - val_acc: 0.4404\n",
      "Training accuracy: 36.97% / Best validation accuracy: 44.04%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.5811 - acc: 0.437 - ETA: 0s - loss: 1.5787 - acc: 0.439 - ETA: 0s - loss: 1.5621 - acc: 0.429 - ETA: 0s - loss: 1.5516 - acc: 0.427 - ETA: 0s - loss: 1.5459 - acc: 0.434 - 0s - loss: 1.5236 - acc: 0.4463 - val_loss: 1.3722 - val_acc: 0.4959\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2678 - acc: 0.531 - ETA: 0s - loss: 1.4497 - acc: 0.453 - ETA: 0s - loss: 1.4517 - acc: 0.459 - ETA: 0s - loss: 1.4403 - acc: 0.465 - ETA: 0s - loss: 1.4336 - acc: 0.468 - 0s - loss: 1.4073 - acc: 0.4842 - val_loss: 1.3149 - val_acc: 0.4743\n",
      "Training accuracy: 48.42% / Best validation accuracy: 47.43%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.3626 - acc: 0.468 - ETA: 0s - loss: 1.3363 - acc: 0.508 - ETA: 0s - loss: 1.3692 - acc: 0.494 - ETA: 0s - loss: 1.3432 - acc: 0.503 - ETA: 0s - loss: 1.3494 - acc: 0.504 - ETA: 0s - loss: 1.3233 - acc: 0.511 - 0s - loss: 1.3241 - acc: 0.5117 - val_loss: 1.3114 - val_acc: 0.4973\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.1333 - acc: 0.625 - ETA: 0s - loss: 1.3039 - acc: 0.557 - ETA: 0s - loss: 1.2675 - acc: 0.559 - ETA: 0s - loss: 1.2765 - acc: 0.550 - ETA: 0s - loss: 1.2590 - acc: 0.548 - ETA: 0s - loss: 1.2647 - acc: 0.539 - 0s - loss: 1.2581 - acc: 0.5412 - val_loss: 1.2854 - val_acc: 0.4743\n",
      "Training accuracy: 54.12% / Best validation accuracy: 47.43%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2557 - acc: 0.625 - ETA: 0s - loss: 1.1957 - acc: 0.571 - ETA: 0s - loss: 1.2166 - acc: 0.547 - ETA: 0s - loss: 1.2112 - acc: 0.543 - ETA: 0s - loss: 1.1919 - acc: 0.552 - ETA: 0s - loss: 1.2058 - acc: 0.551 - 0s - loss: 1.2087 - acc: 0.5490 - val_loss: 1.2708 - val_acc: 0.5244\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.1356 - acc: 0.531 - ETA: 0s - loss: 1.1238 - acc: 0.565 - ETA: 0s - loss: 1.2001 - acc: 0.550 - ETA: 0s - loss: 1.1878 - acc: 0.541 - ETA: 0s - loss: 1.1818 - acc: 0.548 - ETA: 0s - loss: 1.1823 - acc: 0.554 - ETA: 0s - loss: 1.1775 - acc: 0.557 - 0s - loss: 1.1746 - acc: 0.5615 - val_loss: 1.2675 - val_acc: 0.5447\n",
      "Training accuracy: 56.15% / Best validation accuracy: 54.47%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2375 - acc: 0.562 - ETA: 0s - loss: 1.1586 - acc: 0.585 - ETA: 0s - loss: 1.1258 - acc: 0.587 - ETA: 0s - loss: 1.1357 - acc: 0.591 - ETA: 0s - loss: 1.1493 - acc: 0.585 - ETA: 0s - loss: 1.1428 - acc: 0.582 - 0s - loss: 1.1479 - acc: 0.5771 - val_loss: 1.2498 - val_acc: 0.5285\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2354 - acc: 0.562 - ETA: 0s - loss: 1.1793 - acc: 0.579 - ETA: 0s - loss: 1.1770 - acc: 0.573 - ETA: 0s - loss: 1.1700 - acc: 0.569 - ETA: 0s - loss: 1.1460 - acc: 0.574 - ETA: 0s - loss: 1.1339 - acc: 0.577 - 0s - loss: 1.1360 - acc: 0.5778 - val_loss: 1.2478 - val_acc: 0.5650\n",
      "Training accuracy: 57.78% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2513 - acc: 0.484 - ETA: 0s - loss: 1.0773 - acc: 0.598 - ETA: 0s - loss: 1.0997 - acc: 0.592 - ETA: 0s - loss: 1.0797 - acc: 0.594 - ETA: 0s - loss: 1.0762 - acc: 0.600 - ETA: 0s - loss: 1.0927 - acc: 0.598 - 0s - loss: 1.0920 - acc: 0.5981 - val_loss: 1.2988 - val_acc: 0.4824\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.9742 - acc: 0.546 - ETA: 0s - loss: 1.0967 - acc: 0.578 - ETA: 0s - loss: 1.0943 - acc: 0.598 - ETA: 0s - loss: 1.0921 - acc: 0.590 - ETA: 0s - loss: 1.0870 - acc: 0.590 - ETA: 0s - loss: 1.0860 - acc: 0.590 - 0s - loss: 1.0829 - acc: 0.5913 - val_loss: 1.2328 - val_acc: 0.5569\n",
      "Training accuracy: 59.13% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8032 - acc: 0.812 - ETA: 0s - loss: 1.0263 - acc: 0.598 - ETA: 0s - loss: 1.0668 - acc: 0.602 - ETA: 0s - loss: 1.0600 - acc: 0.609 - ETA: 0s - loss: 1.0766 - acc: 0.599 - ETA: 0s - loss: 1.0655 - acc: 0.603 - ETA: 0s - loss: 1.0660 - acc: 0.604 - 0s - loss: 1.0624 - acc: 0.6052 - val_loss: 1.2494 - val_acc: 0.5407\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.0297 - acc: 0.625 - ETA: 0s - loss: 1.0396 - acc: 0.602 - ETA: 0s - loss: 1.0090 - acc: 0.614 - ETA: 0s - loss: 1.0090 - acc: 0.613 - ETA: 0s - loss: 1.0087 - acc: 0.617 - ETA: 0s - loss: 1.0251 - acc: 0.616 - 0s - loss: 1.0268 - acc: 0.6167 - val_loss: 1.2305 - val_acc: 0.5339\n",
      "Training accuracy: 61.67% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.2543 - acc: 0.625 - ETA: 0s - loss: 1.0153 - acc: 0.628 - ETA: 0s - loss: 1.0291 - acc: 0.628 - ETA: 0s - loss: 1.0188 - acc: 0.628 - ETA: 0s - loss: 1.0193 - acc: 0.624 - ETA: 0s - loss: 1.0257 - acc: 0.616 - ETA: 0s - loss: 1.0223 - acc: 0.618 - 0s - loss: 1.0214 - acc: 0.6191 - val_loss: 1.2821 - val_acc: 0.5528\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.0361 - acc: 0.562 - ETA: 0s - loss: 1.0168 - acc: 0.593 - ETA: 0s - loss: 0.9950 - acc: 0.603 - ETA: 0s - loss: 0.9953 - acc: 0.610 - ETA: 0s - loss: 0.9927 - acc: 0.615 - ETA: 0s - loss: 1.0070 - acc: 0.619 - 0s - loss: 1.0105 - acc: 0.6195 - val_loss: 1.2508 - val_acc: 0.5366\n",
      "Training accuracy: 61.95% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.0972 - acc: 0.625 - ETA: 0s - loss: 1.0199 - acc: 0.609 - ETA: 0s - loss: 0.9792 - acc: 0.626 - ETA: 0s - loss: 0.9918 - acc: 0.627 - ETA: 0s - loss: 0.9880 - acc: 0.626 - 0s - loss: 0.9888 - acc: 0.6256 - val_loss: 1.2419 - val_acc: 0.5515\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8187 - acc: 0.687 - ETA: 0s - loss: 0.9881 - acc: 0.641 - ETA: 0s - loss: 0.9585 - acc: 0.649 - ETA: 0s - loss: 0.9616 - acc: 0.645 - ETA: 0s - loss: 0.9753 - acc: 0.643 - 0s - loss: 0.9718 - acc: 0.6479 - val_loss: 1.2801 - val_acc: 0.5122\n",
      "Training accuracy: 64.79% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8817 - acc: 0.687 - ETA: 0s - loss: 0.9405 - acc: 0.654 - ETA: 0s - loss: 0.9305 - acc: 0.676 - ETA: 0s - loss: 0.9424 - acc: 0.673 - ETA: 0s - loss: 0.9380 - acc: 0.667 - ETA: 0s - loss: 0.9522 - acc: 0.654 - 0s - loss: 0.9558 - acc: 0.6499 - val_loss: 1.2754 - val_acc: 0.5488\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7844 - acc: 0.687 - ETA: 0s - loss: 0.9175 - acc: 0.675 - ETA: 0s - loss: 0.9761 - acc: 0.638 - ETA: 0s - loss: 0.9394 - acc: 0.650 - ETA: 0s - loss: 0.9469 - acc: 0.646 - 0s - loss: 0.9431 - acc: 0.6472 - val_loss: 1.2494 - val_acc: 0.4986\n",
      "Training accuracy: 64.72% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8834 - acc: 0.703 - ETA: 0s - loss: 0.9173 - acc: 0.671 - ETA: 0s - loss: 0.9146 - acc: 0.672 - ETA: 0s - loss: 0.9368 - acc: 0.664 - ETA: 0s - loss: 0.9386 - acc: 0.654 - 0s - loss: 0.9377 - acc: 0.6540 - val_loss: 1.2478 - val_acc: 0.5014\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8290 - acc: 0.703 - ETA: 0s - loss: 0.9381 - acc: 0.658 - ETA: 0s - loss: 0.9324 - acc: 0.651 - ETA: 0s - loss: 0.9192 - acc: 0.658 - ETA: 0s - loss: 0.9107 - acc: 0.661 - ETA: 0s - loss: 0.9086 - acc: 0.668 - 0s - loss: 0.9075 - acc: 0.6686 - val_loss: 1.2458 - val_acc: 0.5528\n",
      "Training accuracy: 66.86% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7790 - acc: 0.687 - ETA: 0s - loss: 0.9391 - acc: 0.662 - ETA: 0s - loss: 0.8959 - acc: 0.670 - ETA: 0s - loss: 0.9050 - acc: 0.663 - 0s - loss: 0.9110 - acc: 0.6628 - val_loss: 1.2378 - val_acc: 0.5366\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.9842 - acc: 0.656 - ETA: 0s - loss: 0.9242 - acc: 0.658 - ETA: 0s - loss: 0.8890 - acc: 0.669 - ETA: 0s - loss: 0.8849 - acc: 0.668 - 0s - loss: 0.9035 - acc: 0.6628 - val_loss: 1.2404 - val_acc: 0.5610\n",
      "Training accuracy: 66.28% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8520 - acc: 0.671 - ETA: 0s - loss: 0.9325 - acc: 0.650 - ETA: 0s - loss: 0.8969 - acc: 0.662 - ETA: 0s - loss: 0.8801 - acc: 0.667 - ETA: 0s - loss: 0.8807 - acc: 0.674 - ETA: 0s - loss: 0.8913 - acc: 0.674 - 0s - loss: 0.8901 - acc: 0.6737 - val_loss: 1.2497 - val_acc: 0.5420\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8728 - acc: 0.609 - ETA: 0s - loss: 0.8658 - acc: 0.679 - ETA: 0s - loss: 0.8801 - acc: 0.673 - ETA: 0s - loss: 0.9063 - acc: 0.664 - ETA: 0s - loss: 0.9059 - acc: 0.664 - ETA: 0s - loss: 0.8982 - acc: 0.670 - 0s - loss: 0.9004 - acc: 0.6733 - val_loss: 1.2411 - val_acc: 0.5569\n",
      "Training accuracy: 67.33% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.9267 - acc: 0.609 - ETA: 0s - loss: 0.8750 - acc: 0.684 - ETA: 0s - loss: 0.8305 - acc: 0.708 - ETA: 0s - loss: 0.8546 - acc: 0.693 - ETA: 0s - loss: 0.8568 - acc: 0.685 - ETA: 0s - loss: 0.8671 - acc: 0.678 - ETA: 0s - loss: 0.8750 - acc: 0.672 - 0s - loss: 0.8709 - acc: 0.6747 - val_loss: 1.2333 - val_acc: 0.5203\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 1.0439 - acc: 0.609 - ETA: 0s - loss: 0.8350 - acc: 0.706 - ETA: 0s - loss: 0.8791 - acc: 0.685 - ETA: 0s - loss: 0.8909 - acc: 0.677 - ETA: 0s - loss: 0.8685 - acc: 0.684 - 0s - loss: 0.8663 - acc: 0.6852 - val_loss: 1.2029 - val_acc: 0.5610\n",
      "Training accuracy: 68.52% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8261 - acc: 0.656 - ETA: 0s - loss: 0.8328 - acc: 0.690 - ETA: 0s - loss: 0.8557 - acc: 0.681 - ETA: 0s - loss: 0.8393 - acc: 0.687 - ETA: 0s - loss: 0.8481 - acc: 0.680 - 0s - loss: 0.8467 - acc: 0.6811 - val_loss: 1.2629 - val_acc: 0.5623\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.9399 - acc: 0.734 - ETA: 0s - loss: 0.8010 - acc: 0.727 - ETA: 0s - loss: 0.8219 - acc: 0.711 - ETA: 0s - loss: 0.8091 - acc: 0.704 - ETA: 0s - loss: 0.8354 - acc: 0.691 - ETA: 0s - loss: 0.8260 - acc: 0.696 - ETA: 0s - loss: 0.8450 - acc: 0.687 - 0s - loss: 0.8353 - acc: 0.6910 - val_loss: 1.2172 - val_acc: 0.5420\n",
      "Training accuracy: 69.10% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8099 - acc: 0.703 - ETA: 0s - loss: 0.8225 - acc: 0.681 - ETA: 0s - loss: 0.8207 - acc: 0.682 - ETA: 0s - loss: 0.8183 - acc: 0.683 - ETA: 0s - loss: 0.8123 - acc: 0.691 - ETA: 0s - loss: 0.8171 - acc: 0.690 - 0s - loss: 0.8145 - acc: 0.6940 - val_loss: 1.3004 - val_acc: 0.5271\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7842 - acc: 0.703 - ETA: 0s - loss: 0.8216 - acc: 0.703 - ETA: 0s - loss: 0.8139 - acc: 0.696 - ETA: 0s - loss: 0.8013 - acc: 0.706 - ETA: 0s - loss: 0.8022 - acc: 0.700 - ETA: 0s - loss: 0.7969 - acc: 0.698 - ETA: 0s - loss: 0.8030 - acc: 0.696 - 0s - loss: 0.8185 - acc: 0.6896 - val_loss: 1.2024 - val_acc: 0.5515\n",
      "Training accuracy: 68.96% / Best validation accuracy: 56.50%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8465 - acc: 0.640 - ETA: 0s - loss: 0.7561 - acc: 0.704 - ETA: 0s - loss: 0.7969 - acc: 0.691 - ETA: 0s - loss: 0.8141 - acc: 0.683 - ETA: 0s - loss: 0.8101 - acc: 0.690 - ETA: 0s - loss: 0.8225 - acc: 0.683 - 0s - loss: 0.8290 - acc: 0.6801 - val_loss: 1.2211 - val_acc: 0.5542\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.6696 - acc: 0.750 - ETA: 0s - loss: 0.8060 - acc: 0.701 - ETA: 0s - loss: 0.7934 - acc: 0.702 - ETA: 0s - loss: 0.8056 - acc: 0.696 - ETA: 0s - loss: 0.8035 - acc: 0.696 - ETA: 0s - loss: 0.7969 - acc: 0.697 - ETA: 0s - loss: 0.8037 - acc: 0.693 - 0s - loss: 0.7996 - acc: 0.6943 - val_loss: 1.2383 - val_acc: 0.5786\n",
      "Training accuracy: 69.43% / Best validation accuracy: 57.86%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7728 - acc: 0.765 - ETA: 0s - loss: 0.7824 - acc: 0.734 - ETA: 0s - loss: 0.7921 - acc: 0.715 - ETA: 0s - loss: 0.7866 - acc: 0.714 - ETA: 0s - loss: 0.7934 - acc: 0.705 - ETA: 0s - loss: 0.7891 - acc: 0.705 - ETA: 0s - loss: 0.7876 - acc: 0.705 - 0s - loss: 0.7947 - acc: 0.7021 - val_loss: 1.2568 - val_acc: 0.5664\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.9274 - acc: 0.656 - ETA: 0s - loss: 0.8130 - acc: 0.675 - ETA: 0s - loss: 0.7626 - acc: 0.707 - ETA: 0s - loss: 0.7727 - acc: 0.706 - ETA: 0s - loss: 0.7831 - acc: 0.702 - ETA: 0s - loss: 0.7912 - acc: 0.699 - 0s - loss: 0.7908 - acc: 0.6998 - val_loss: 1.2285 - val_acc: 0.5501\n",
      "Training accuracy: 69.98% / Best validation accuracy: 57.86%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.750 - ETA: 0s - loss: 0.7271 - acc: 0.734 - ETA: 0s - loss: 0.7794 - acc: 0.709 - ETA: 0s - loss: 0.7694 - acc: 0.713 - ETA: 0s - loss: 0.7829 - acc: 0.710 - ETA: 0s - loss: 0.7836 - acc: 0.710 - ETA: 0s - loss: 0.7865 - acc: 0.705 - 0s - loss: 0.7878 - acc: 0.7052 - val_loss: 1.2686 - val_acc: 0.5623\n",
      "Epoch 2/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7027 - acc: 0.718 - ETA: 0s - loss: 0.7275 - acc: 0.716 - ETA: 0s - loss: 0.7351 - acc: 0.708 - ETA: 0s - loss: 0.7445 - acc: 0.713 - ETA: 0s - loss: 0.7567 - acc: 0.705 - ETA: 0s - loss: 0.7645 - acc: 0.699 - ETA: 0s - loss: 0.7668 - acc: 0.700 - ETA: 0s - loss: 0.7629 - acc: 0.701 - ETA: 0s - loss: 0.7649 - acc: 0.701 - 0s - loss: 0.7661 - acc: 0.7004 - val_loss: 1.1978 - val_acc: 0.5718\n",
      "Training accuracy: 70.04% / Best validation accuracy: 57.86%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "2951/2951 [==============================] - ETA: 0s - loss: 0.8970 - acc: 0.609 - ETA: 0s - loss: 0.7819 - acc: 0.696 - ETA: 0s - loss: 0.7658 - acc: 0.699 - ETA: 0s - loss: 0.7666 - acc: 0.706 - ETA: 0s - loss: 0.7710 - acc: 0.699 - ETA: 0s - loss: 0.7757 - acc: 0.698 - ETA: 0s - loss: 0.7797 - acc: 0.694 - ETA: 0s - loss: 0.7789 - acc: 0.693 - ETA: 0s - loss: 0.7720 - acc: 0.696 - 0s - loss: 0.7666 - acc: 0.6981 - val_loss: 1.2305 - val_acc: 0.5583\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2951/2951 [==============================] - ETA: 0s - loss: 0.7399 - acc: 0.687 - ETA: 0s - loss: 0.7859 - acc: 0.680 - ETA: 0s - loss: 0.7584 - acc: 0.699 - ETA: 0s - loss: 0.7475 - acc: 0.701 - ETA: 0s - loss: 0.7841 - acc: 0.692 - ETA: 0s - loss: 0.7828 - acc: 0.688 - ETA: 0s - loss: 0.7645 - acc: 0.698 - ETA: 0s - loss: 0.7600 - acc: 0.702 - ETA: 0s - loss: 0.7516 - acc: 0.705 - 0s - loss: 0.7534 - acc: 0.7045 - val_loss: 1.2897 - val_acc: 0.5366\n",
      "Training accuracy: 70.45% / Best validation accuracy: 57.86%\n",
      "Train on 2951 samples, validate on 738 samples\n",
      "Epoch 1/2\n",
      "  64/2951 [..............................] - ETA: 0s - loss: 0.6324 - acc: 0.7656"
     ]
    }
   ],
   "source": [
    "train_nn_model(model, train_set, encoded_y, filename = 'try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the xgboost classfication model\n",
    "#first deal with the input label, transfrom it from 1-9 to 0-8(required by the xgboost)\n",
    "for i in range(len(train_y)):\n",
    "    train_y[i] -=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.11096\tvalid-mlogloss:2.13755\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:0.546776\tvalid-mlogloss:1.16003\n",
      "[100]\ttrain-mlogloss:0.200471\tvalid-mlogloss:0.985421\n",
      "[150]\ttrain-mlogloss:0.089525\tvalid-mlogloss:0.949457\n",
      "[200]\ttrain-mlogloss:0.047857\tvalid-mlogloss:0.95521\n",
      "[250]\ttrain-mlogloss:0.030732\tvalid-mlogloss:0.97078\n",
      "Stopping. Best iteration:\n",
      "[171]\ttrain-mlogloss:0.067177\tvalid-mlogloss:0.948514\n",
      "\n",
      "0.948514315681\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "y_predict = xgbclassifier(train_set, train_y, test_set, 5, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savesubmisstion(y_predict, test_x, filename = \"submission_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
